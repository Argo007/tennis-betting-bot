name: Tennis Picks (ATP/WTA)

on:
  schedule:
    - cron: "0 8 * * *"      # 08:00 UTC daily
  workflow_dispatch: {}

concurrency:
  group: tennis-picks
  cancel-in-progress: true

jobs:
  picks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: |
          python -m pip install --upgrade pip
          pip install pandas requests

      # Build quick Elo (2 seasons) – still light, but you can remove if you want pure market
      - name: Download ATP/WTA results
        run: |
          mkdir -p matches
          curl -sSL -o matches/atp_matches_2023.csv https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_2023.csv
          curl -sSL -o matches/atp_matches_2024.csv https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_2024.csv
          curl -sSL -o matches/wta_matches_2023.csv https://raw.githubusercontent.com/JeffSackmann/tennis_wta/master/wta_matches_2023.csv
          curl -sSL -o matches/wta_matches_2024.csv https://raw.githubusercontent.com/JeffSackmann/tennis_wta/master/wta_matches_2024.csv
      - name: Generate Elo
        run: |
          python - <<'PY'
          import pandas as pd, glob, os
          START, K = 1500, 32
          def exp(a,b): return 1/(1+10**((b-a)/400))
          def upd(a,b,s): return a + K*(s-exp(a,b))
          def calc(pattern):
              files = glob.glob(pattern)
              df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)
              E = {}
              for _,r in df.iterrows():
                  w,l = r['winner_name'], r['loser_name']
                  ew, el = E.get(w,START), E.get(l,START)
                  E[w] = upd(ew,el,1); E[l] = upd(el,ew,0)
              return pd.DataFrame([{'player':k,'elo':v} for k,v in E.items()])
          os.makedirs("data", exist_ok=True)
          calc("matches/atp_matches_*.csv").to_csv("data/atp_elo.csv", index=False)
          calc("matches/wta_matches_*.csv").to_csv("data/wta_elo.csv", index=False)
          PY

      - name: Publish upcoming picks (quarter-Kelly + CLV filter)
        env:
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
          REGION: "eu"            # odds API region
          LOOKAHEAD_H: "168"      # 7 days window
          START_BUFFER_MIN: "5"   # treat <5m as live-ish
          CLV_MIN_PCT: "1.0"      # require best price ≥ (1+1%) of market median
          MIN_CONF: "50"
          ODDS_DOG_MIN: "2.20"
          ODDS_DOG_MAX: "4.50"
          ODDS_FAV_MIN: "1.30"
          ODDS_FAV_MAX: "1.80"
          TOP_DOGS: "3"
          TOP_FAVS: "2"
        run: |
          python - <<'PY'
          import os, sys, math, re, time, requests, pandas as pd, datetime as dt

          # --- config ---
          def getenv(k, cast, default):
              try: return cast(os.getenv(k, str(default)))
              except: return default
          API   = os.getenv("ODDS_API_KEY","")
          if not API: print("Missing ODDS_API_KEY"); sys.exit(1)
          REGION = os.getenv("REGION","eu")
          LOOKH  = getenv("LOOKAHEAD_H", int, 168)
          BUFMIN = getenv("START_BUFFER_MIN", int, 5)
          CLV_MIN = getenv("CLV_MIN_PCT", float, 1.0) / 100.0
          MIN_CONF = getenv("MIN_CONF", int, 50)
          DOG_MIN, DOG_MAX = getenv("ODDS_DOG_MIN", float, 2.20), getenv("ODDS_DOG_MAX", float, 4.50)
          FAV_MIN, FAV_MAX = getenv("ODDS_FAV_MIN", float, 1.30), getenv("ODDS_FAV_MAX", float, 1.80)
          TOP_DOGS, TOP_FAVS = getenv("TOP_DOGS", int, 3), getenv("TOP_FAVS", int, 2)

          NOW = dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)
          WINDOW_END = NOW + dt.timedelta(hours=LOOKH)
          BUFFER_CUT = NOW + dt.timedelta(minutes=BUFMIN)

          # --- Elo helpers ---
          def load_elo(path):
              if not os.path.exists(path): return {}
              df = pd.read_csv(path)
              return dict(zip(df["player"].astype(str), df["elo"].astype(float)))
          ATP_ELO = load_elo("data/atp_elo.csv")
          WTA_ELO = load_elo("data/wta_elo.csv")
          def elo_prob(tour, a, b):
              E = ATP_ELO if tour=="ATP" else WTA_ELO
              ea = E.get(a,1500.0); eb = E.get(b,1500.0)
              return 1.0/(1.0+10**((eb-ea)/400.0))

          # --- odds fetch ---
          sess = requests.Session()
          sess.headers.update({"User-Agent":"tennis-picks/1.1"})
          def get(url, params, tries=3):
              for i in range(tries):
                  r = sess.get(url, params=params, timeout=15)
                  if r.status_code==200: return r.json()
                  if r.status_code in (429,500,502,503,504): time.sleep(1.5*(i+1)); continue
                  r.raise_for_status()
              return []
          def sport_url(key): return f"https://api.the-odds-api.com/v4/sports/{key}/odds"
          sports = [("ATP","tennis_atp"), ("WTA","tennis_wta")]

          rows=[]
          for tour, key in sports:
              data = get(sport_url(key), {"apiKey":API,"regions":REGION,"markets":"h2h","oddsFormat":"decimal"})
              for ev in data:
                  start = pd.to_datetime(ev.get("commence_time"), utc=True, errors="coerce")
                  if start is pd.NaT or not (BUFFER_CUT <= start <= WINDOW_END): 
                      continue
                  status = (ev.get("status") or "").lower()
                  if re.search(r"(live|in[-\s_]?play|started|progress)", status): 
                      continue

                  home = ev.get("home_team")
                  away = ev.get("away_team")
                  if not home or not away: 
                      teams = ev.get("participants") or ev.get("teams") or []
                      if len(teams)>=2: home, away = teams[0], teams[1]
                  if not home or not away: 
                      continue

                  # collect prices across books for median & best
                  price_map = {}     # {runner: [prices]}
                  best_price = {}    # {runner: best_decimal}
                  for bm in ev.get("bookmakers",[]):
                      for m in bm.get("markets",[]):
                          if m.get("key")!="h2h": continue
                          for o in m.get("outcomes",[]):
                              name = o.get("name"); price = o.get("price")
                              if not name or not price: continue
                              price_map.setdefault(name, []).append(float(price))
                              best_price[name] = max(best_price.get(name, 0.0), float(price))

                  if home not in best_price or away not in best_price: 
                      continue
                  # market "consensus" = median
                  import statistics as S
                  def consensus(name): 
                      arr = price_map.get(name, [])
                      return S.median(arr) if arr else None
                  cons_home = consensus(home)
                  cons_away = consensus(away)
                  if not cons_home or not cons_away: 
                      continue

                  # Build both sides
                  for a,b in [(home,away),(away,home)]:
                      best = best_price[a]; cons = (cons_home if a==home else cons_away)
                      if cons<=1 or best<=1: 
                          continue
                      # CLV edge right now vs median
                      clv_edge = (best - cons)/cons
                      if clv_edge < CLV_MIN: 
                          continue

                      # probs
                      p_market = 1.0/cons              # use consensus prob, not our best price
                      p_elo    = elo_prob(tour, a, b)
                      p_blend  = 0.5*p_market + 0.5*p_elo

                      # value, Kelly & quarter-Kelly
                      b_mult = best - 1.0
                      evu = best*p_blend - 1.0
                      kelly = max(0.0, (b_mult*p_blend - (1-p_blend))/b_mult) if b_mult>0 else 0.0
                      stake_q = 0.25 * kelly   # << quarter-Kelly

                      conf = 50 + 50*abs(p_elo - 0.5)
                      rows.append({
                        "tour": tour, "player": a, "opponent": b,
                        "best_odds": best, "consensus_odds": cons, "clv_edge": clv_edge,
                        "blended_prob": p_blend, "ev_per_unit": evu,
                        "kelly": kelly, "stake_q": stake_q,
                        "confidence": conf, "commence_dt": start
                      })

          df = pd.DataFrame(rows)
          if df.empty:
              with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as f:
                  f.write(f"_No upcoming odds within {LOOKH}h (filtered at {NOW.strftime('%Y-%m-%d %H:%M UTC')})._\n")
              sys.exit(0)

          # dedup per match, keep higher EV/u
          df["match_id"] = df.apply(lambda r: " :: ".join(sorted([r["player"], r["opponent"]])), axis=1)
          df = df.sort_values(["ev_per_unit","confidence","commence_dt"], ascending=[False,False,True]).groupby("match_id", as_index=False).first()
          df["eta_min"] = (df["commence_dt"] - NOW).dt.total_seconds()/60

          def picks(sub, lo, hi, n, min_conf=MIN_CONF):
              f = sub[(sub["best_odds"].between(lo,hi)) &
                      (sub["ev_per_unit"]>0) &
                      (sub["confidence"]>=min_conf) &
                      (sub["stake_q"]>0)]
              return f.sort_values(["ev_per_unit","stake_q","eta_min"], ascending=[False,False,True]).head(n)

          def bullets(x):
              if x.empty: return "_None_"
              out=[]
              for _,r in x.iterrows():
                  start_iso = r["commence_dt"].strftime("%Y-%m-%d %H:%M UTC")
                  out.append(
                    f"- {r['player']} vs {r['opponent']} @ {r['best_odds']:.2f} "
                    f"(cons {r['consensus_odds']:.2f}, CLV {r['clv_edge']*100:.1f}%, "
                    f"p={r['blended_prob']:.2f}, EV/u={r['ev_per_unit']:.2f}, "
                    f"Kelly={r['kelly']:.3f}, ¼Kelly={r['stake_q']:.3f}) — {start_iso} (ETA {int(r['eta_min'])}m)"
                  )
              return "\n".join(out)

          with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as f:
              f.write(f"_Filtered at {NOW.strftime('%Y-%m-%d %H:%M UTC')} — upcoming-only (≥{BUFMIN}m, ≤{LOOKH}h) · CLV ≥ {int(CLV_MIN*100)}% vs market median · stakes = quarter-Kelly._\n\n")
              for tour in ["ATP","WTA"]:
                  sub = df[df["tour"]==tour]
                  dogs = picks(sub, DOG_MIN, DOG_MAX, TOP_DOGS)
                  favs = picks(sub, FAV_MIN, FAV_MAX, TOP_FAVS)
                  f.write(f"## 🎯 {tour} Smart Underdogs (Top {TOP_DOGS})\n{bullets(dogs)}\n\n")
                  f.write(f"## 🛡 {tour} Safe High-Value Favorites (Top {TOP_FAVS})\n{bullets(favs)}\n\n")
          PY
