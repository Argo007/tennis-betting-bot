name: Tennis Picks (ATP/WTA)

on:
  schedule:
    - cron: "0 8 * * *"    # 08:00 UTC daily
  workflow_dispatch: {}

jobs:
  picks:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests

      # --- build Elo from last two seasons (simple but effective) ---
      - name: Download ATP/WTA results
        run: |
          mkdir -p matches
          curl -sSL -o matches/atp_matches_2023.csv https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_2023.csv
          curl -sSL -o matches/atp_matches_2024.csv https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_2024.csv
          curl -sSL -o matches/wta_matches_2023.csv https://raw.githubusercontent.com/JeffSackmann/tennis_wta/master/wta_matches_2023.csv
          curl -sSL -o matches/wta_matches_2024.csv https://raw.githubusercontent.com/JeffSackmann/tennis_wta/master/wta_matches_2024.csv

      - name: Generate Elo
        run: |
          python - <<'PY'
          import pandas as pd, glob, os
          START, K = 1500, 32
          def exp(a,b): return 1/(1+10**((b-a)/400))
          def upd(a,b,s): return a + K*(s-exp(a,b))
          def calc(pattern):
              files = glob.glob(pattern)
              df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)
              E = {}
              for _,r in df.iterrows():
                  w,l = r['winner_name'], r['loser_name']
                  ew, el = E.get(w,START), E.get(l,START)
                  E[w] = upd(ew,el,1); E[l] = upd(el,ew,0)
              return pd.DataFrame([{'player':k,'elo':v} for k,v in E.items()]).sort_values('elo',ascending=False)
          os.makedirs("data", exist_ok=True)
          calc("matches/atp_matches_*.csv").to_csv("data/atp_elo.csv", index=False)
          calc("matches/wta_matches_*.csv").to_csv("data/wta_elo.csv", index=False)
          print("Elo ready.")
          PY

      # --- run your model script to produce value_picks_pro.csv ---
      - name: Run model
        env:
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
        run: |
          python tennis_value_picks_pro.py --region eu --lookahead-h 168 --out value_picks_pro.csv

      # --- pretty shortlist: upcoming-only (24h), Kelly-only, optional CLV; dedup inside buckets ---
      - name: Print shortlist (3 Dogs, 2 Favs per tour)
        run: |
          python - <<'PY'
          import pandas as pd, os, re, datetime as dt

          # Settings
          BUF_MIN   = 5          # treat <5m as live-ish
          ETA_H     = 24         # only show matches starting within 24h
          MIN_CONF  = 50
          CLV_MIN   = 0.01       # apply only if 'consensus_odds' exists (>=1% advantage)
          TOP_DOGS, TOP_FAVS = 3, 2
          DOG_MIN, DOG_MAX = 1.90, 6.00   # widened so dogs actually show
          FAV_MIN, FAV_MAX = 1.15, 2.00

          now = dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)
          cut = now + dt.timedelta(minutes=BUF_MIN)
          eta_cap = now + dt.timedelta(hours=ETA_H)

          df = pd.read_csv("value_picks_pro.csv")

          # numeric coercion
          for c in ["blended_prob","best_odds","ev_per_unit","kelly_fraction","confidence"]:
              if c in df.columns:
                  df[c] = pd.to_numeric(df[c], errors="coerce")
          if "confidence" not in df.columns:
              df["confidence"] = 0

          # start time (prefer explicit UTC)
          if "commence_time_utc" in df.columns:
              df["commence_dt"] = pd.to_datetime(df["commence_time_utc"], utc=True, errors="coerce")
          elif "commence_time" in df.columns:
              df["commence_dt"] = pd.to_datetime(df["commence_time"], utc=True, errors="coerce")
          else:
              df["commence_dt"] = pd.NaT

          # drop live/in-play
          live_re = re.compile(r"(live|in[-\\s_]?play|started|progress)", re.I)
          if "is_live" in df.columns:
              df = df[~df["is_live"].fillna(False).astype(bool)]
          if "status" in df.columns:
              df = df[~df["status"].astype(str).str.contains(live_re, na=False)]

          # upcoming-only within 24h
          df = df[df["commence_dt"].notna() & (df["commence_dt"] >= cut) & (df["commence_dt"] <= eta_cap)]

          # required columns
          need = ["player","opponent","tour","best_odds","blended_prob","commence_dt"]
          if any(col not in df.columns for col in need):
              with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as f:
                  f.write("Required columns missing in value_picks_pro.csv.\n")
              raise SystemExit(0)

          # Kelly (use provided; else compute) ‚Äî decimal odds
          def kelly_from(p, odds):
              if pd.isna(p) or pd.isna(odds) or odds <= 1: return 0.0
              b = odds - 1.0
              return max(0.0, (b*p - (1.0 - p))/b) if b > 0 else 0.0
          if "kelly_fraction" in df.columns and df["kelly_fraction"].notna().any():
              df["kelly"] = pd.to_numeric(df["kelly_fraction"], errors="coerce").fillna(0.0)
          else:
              df["kelly"] = [kelly_from(p, o) for p, o in zip(df["blended_prob"], df["best_odds"])]

          # Optional CLV (only if consensus_odds exists)
          clv_used = False
          if "consensus_odds" in df.columns:
              df["consensus_odds"] = pd.to_numeric(df["consensus_odds"], errors="coerce")
              if df["consensus_odds"].notna().any():
                  df["clv_edge"] = (df["best_odds"] - df["consensus_odds"]) / df["consensus_odds"]
                  df = df[df["clv_edge"].notna() & (df["clv_edge"] >= CLV_MIN)]
                  clv_used = True

          if df.empty:
              with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as f:
                  f.write("No eligible picks in 24h window after filters.\n")
              raise SystemExit(0)

          # Keep both sides; dedup happens inside bucket picks
          df["match_id"] = df.apply(lambda r: " :: ".join(sorted([str(r["player"]), str(r["opponent"])])), axis=1)
          df["eta_min"] = (df["commence_dt"] - now).dt.total_seconds()/60.0

          # helpers
          def eta_fmt(m):
              m = int(round(m)); h, mm = divmod(m, 60)
              return f"{h}h {mm:02d}m" if h else f"{mm}m"
          def ts_fmt(ts): return ts.strftime("%Y-%m-%d %H:%M UTC")

          # Filter -> sort -> dedup per match inside each bucket
          def bucket_picks(sub, lo, hi, n):
              f = sub[(sub["best_odds"].between(lo, hi)) &
                      (sub["confidence"].fillna(0) >= MIN_CONF)]
              if f.empty: return f
              f = f.sort_values(["kelly","eta_min"], ascending=[False, True])
              f = f.groupby("match_id", as_index=False).first()
              return f.head(n)

          def section(title, content):
              return f"## üèÜ **{title}**\n\n{content}\n"

          def list_block(x):
              if x.empty: return "_None_"
              lines=[]
              for i,(_,r) in enumerate(x.iterrows(), start=1):
                  ln = (
                      f"{i}. **{r['player']}** vs *{r['opponent']}* ‚Äî **{r['best_odds']:.2f}** "
                      f"_(p={r['blended_prob']:.2f}, Kelly={r['kelly']:.3f}"
                  )
                  if "clv_edge" in r and pd.notna(r["clv_edge"]): ln += f", CLV=+{r['clv_edge']*100:.1f}%"
                  ln += f")_\n   üóì **{ts_fmt(r['commence_dt'])}** ‚Ä¢ ETA: {eta_fmt(r['eta_min'])}"
                  lines.append(ln)
              return "\n".join(lines)

          header = f"_Filtered at {now.strftime('%Y-%m-%d %H:%M UTC')} ¬∑ upcoming-only (‚â§ {ETA_H}h, buffer {BUF_MIN}m)._"
          header += f" _CLV ‚â• {int(CLV_MIN*100)}% applied._" if clv_used else " _CLV check skipped (no consensus_odds column)._"
          out = [header, ""]

          for tour in ["ATP","WTA"]:
              sub = df[df["tour"].astype(str).str.upper()==tour]
              dogs = bucket_picks(sub, DOG_MIN, DOG_MAX, TOP_DOGS)
              favs = bucket_picks(sub, FAV_MIN, FAV_MAX, TOP_FAVS)
              out.append(section(f"{tour} Underdogs (Top {TOP_DOGS})", list_block(dogs)))
              out.append(section(f"{tour} Favorites (Top {TOP_FAVS})",   list_block(favs)))

          with open(os.environ["GITHUB_STEP_SUMMARY"], "a") as f:
              f.write("\n".join(out))
          PY
