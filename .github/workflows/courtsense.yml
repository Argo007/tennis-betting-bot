name: Courtsense (Build + Normalize + Backtest)

on:
  workflow_dispatch:
    inputs:
      years_csv:
        description: "Years space-separated"
        required: false
        default: "2021 2022 2023 2024 2025"
      start_date:
        description: "Backtest start"
        required: false
        default: "2021-01-01"
      end_date:
        description: "Backtest end"
        required: false
        default: "2025-12-31"
      bands:
        description: "dog=min,max;fav=min,max"
        required: false
        default: "dog=2.20,4.50;fav=1.15,2.00"
      grid:
        description: "min_edge=...;kelly_cap=...;te8_dog=...;te8_fav=..."
        required: false
        default: "min_edge=0.02,0.03,0.04;kelly_cap=0.10,0.15,0.20;te8_dog=0.58,0.60;te8_fav=0.48,0.50"
      use_synth:
        description: "Seed synthetic odds if none found"
        required: true
        type: choice
        default: "yes"
        options: ["yes","no"]

permissions:
  contents: read

env:
  TZ: Europe/Amsterdam
  YEARS_CSV: ${{ github.event.inputs.years_csv || '2021 2022 2023 2024 2025' }}

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy requests openpyxl rapidfuzz unidecode tabulate

      - name: Ensure dirs
        run: mkdir -p data/raw/odds data/raw/odds_normalized data

      - name: Seed synthetic odds if none
        if: ${{ github.event.inputs.use_synth == 'yes' }}
        run: |
          shopt -s nullglob
          cnt=(data/raw/odds/* data/raw/odds_normalized/*)
          if [ ${#cnt[@]} -eq 0 ]; then
            cat > data/raw/odds/sample_odds.csv <<'CSV'
date,player_a,player_b,odds_a,odds_b
2023-06-11,Novak Djokovic,Casper Ruud,1.33,3.4
2022-07-10,Novak Djokovic,Nick Kyrgios,1.33,3.6
2021-09-12,Daniil Medvedev,Novak Djokovic,2.6,1.55
2024-01-28,Jannik Sinner,Daniil Medvedev,1.85,2.05
2021-06-12,Barbora Krejcikova,Anastasia Pavlyuchenkova,1.75,2.1
2023-07-15,Marketa Vondrousova,Ons Jabeur,2.3,1.65
2024-07-13,Barbora Krejcikova,Jasmine Paolini,1.6,2.4
CSV
            echo "Seeded sample_odds.csv"
          fi

      - name: Build dataset (link odds to Sackmann + Elo) â€” writes headers even if 0 rows
        run: |
          python - <<'PY'
          import os, io, time, glob, re, pandas as pd, requests
          from unidecode import unidecode
          YEARS=[int(x) for x in os.getenv("YEARS_CSV","2021 2022 2023 2024 2025").split()]
          def fetch(repo, tour, y):
              u=f"https://raw.githubusercontent.com/JeffSackmann/{repo}/master/{tour}_matches_{y}.csv"
              for _ in (0,1,2):
                  try:
                      r=requests.get(u,timeout=12); r.raise_for_status()
                      return pd.read_csv(io.StringIO(r.text))
                  except Exception: time.sleep(1.2)
              return pd.DataFrame()
          atp=pd.concat([fetch("tennis_atp","atp",y) for y in YEARS], ignore_index=True)
          wta=pd.concat([fetch("tennis_wta","wta",y) for y in YEARS], ignore_index=True)
          def norm(x):
              x=unidecode(str(x)).lower(); x=re.sub(r"[^a-z ]"," ",x)
              return re.sub(r"\s+"," ",x).strip()
          for df,t in ((atp,"ATP"),(wta,"WTA")):
              if df.empty: continue
              df["tour"]=t
              df["date"]=pd.to_datetime(df["tourney_date"].astype(str),format="%Y%m%d",errors="coerce").dt.normalize()
              df["w_norm"]=df["winner_name"].map(norm); df["l_norm"]=df["loser_name"].map(norm)
              df["pair"]=df.apply(lambda r:" vs ".join(sorted([r["w_norm"],r["l_norm"]])),axis=1)
          results=pd.concat([atp,wta],ignore_index=True)

          # Elo (quick)
          def build_elo(df):
              E={"ATP":{}, "WTA":{}}
              K=32
              for _,r in df.sort_values(["tour","date"]).iterrows():
                  t,w,l=r["tour"],r["w_norm"],r["l_norm"]
                  ew=E[t].get(w,1500.0); el=E[t].get(l,1500.0)
                  exp=1/(1+10**((el-ew)/400))
                  E[t][w]=ew+K*(1-exp); E[t][l]=el+K*(0-(1-exp))
              return E
          ELO=build_elo(results)
          os.makedirs("data", exist_ok=True)
          pd.DataFrame([{"player":k,"elo":v} for k,v in ELO["ATP"].items()]).to_csv("data/atp_elo.csv", index=False)
          pd.DataFrame([{"player":k,"elo":v} for k,v in ELO["WTA"].items()]).to_csv("data/wta_elo.csv", index=False)

          # read odds
          d="data/raw/odds_normalized" if glob.glob("data/raw/odds_normalized/*.csv") else "data/raw/odds"
          files=glob.glob(d+"/*.csv")
          odds=pd.concat([pd.read_csv(p) for p in files], ignore_index=True) if files else pd.DataFrame()
          if not odds.empty:
              odds["date"]=pd.to_datetime(odds["date"],errors="coerce").dt.normalize()
              odds=odds.dropna(subset=["date","player_a","player_b","odds_a","odds_b"])
          def link_row(r):
              if results.empty: return None
              import pandas as pd
              pair=" vs ".join(sorted([norm(r["player_a"]),norm(r["player_b"])]))
              cand=results[(results["pair"]==pair)&(results["date"].between(r["date"]-pd.Timedelta(days=10),
                                                                            r["date"]+pd.Timedelta(days=10)))]
              if cand.empty: return None
              m=cand.iloc[(cand["date"]-r["date"]).abs().argsort().iloc[0]]
              w,l=m["w_norm"],m["l_norm"]; pn=norm(r["player_a"]); res = 1 if pn==w else 0
              def elo_of(name,tour): 
                  pool=ELO["ATP"] if tour=="ATP" else ELO["WTA"]
                  return pool.get(name,1500.0)
              ep = elo_of(w,m["tour"]) if pn==w else elo_of(l,m["tour"])
              eo = elo_of(l,m["tour"]) if pn==w else elo_of(w,m["tour"])
              return {
                "date": m["date"].date(), "tour": m["tour"], "tournament": m.get("tourney_name",""),
                "round": m.get("round",""), "player": r["player_a"], "opponent": r["player_b"],
                "odds": float(r["odds_a"]), "opp_odds": float(r["odds_b"]),
                "result": int(res), "elo_player": ep, "elo_opponent": eo, "surface": m.get("surface","")
              }
          cols=["date","tour","tournament","round","player","opponent","odds","opp_odds","result","elo_player","elo_opponent","surface"]
          out = pd.DataFrame([x for x in (link_row(x) for _,x in odds.iterrows()) if x], columns=cols) if not odds.empty else pd.DataFrame(columns=cols)
          out.to_csv("data/historical_matches.csv", index=False)  # ALWAYS headers
          print(f"Linked rows: {len(out)}")
          PY

      - name: Upload dataset artifact
        uses: actions/upload-artifact@v4
        with:
          name: courtsense-dataset
          path: |
            data/historical_matches.csv
            data/atp_elo.csv
            data/wta_elo.csv

  backtest:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pandas tabulate
      - name: Download dataset
        uses: actions/download-artifact@v4
        with:
          name: courtsense-dataset
          path: data

      - name: Skip nicely if 0 rows
        id: probe
        run: |
          python - <<'PY'
          import pandas as pd, sys, json
          try:
              df=pd.read_csv("data/historical_matches.csv")
          except Exception as e:
              print("rows=0; reason=read_error:", e); sys.exit(0)
          n=len(df)
          print("rows=", n)
          open("rows.txt","w").write(str(n))
          PY

      - name: Run backtest (with matrix)
        run: |
          if [ ! -s data/historical_matches.csv ]; then
            echo "# TE8 Backtest Summary" > backtest_summary.md
            echo "" >> backtest_summary.md
            echo "_Dataset file missing or zero size._" >> backtest_summary.md
          elif [ "$(cat rows.txt)" = "0" ]; then
            echo "# TE8 Backtest Summary" > backtest_summary.md
            echo "" >> backtest_summary.md
            echo "_No rows to backtest (join matched 0 games)._ " >> backtest_summary.md
          else
            python backtest_te8.py \
              --input data/historical_matches.csv \
              --start "${{ github.event.inputs.start_date }}" \
              --end   "${{ github.event.inputs.end_date }}" \
              --bands "${{ github.event.inputs.bands }}" \
              --grid  "${{ github.event.inputs.grid }}" \
              --out-csv backtest_results.csv \
              --summary backtest_summary.md
          fi

      - name: Publish summary
        run: |
          echo "## Courtsense Backtest" >> "$GITHUB_STEP_SUMMARY"
          cat backtest_summary.md >> "$GITHUB_STEP_SUMMARY" || echo "_No summary produced._" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backtest-output
          path: |
            backtest_results.csv
            backtest_summary.md
            grid_results.csv
          if-no-files-found: warn
