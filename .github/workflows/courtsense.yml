name: Courtsense (Build + Backtest)

on:
  workflow_dispatch:
    inputs:
      years_csv:
        description: "Years (space-separated)"
        required: false
        default: "2021 2022 2023 2024 2025"
      start_date:
        description: "Backtest start (YYYY-MM-DD)"
        required: false
        default: "2021-01-01"
      end_date:
        description: "Backtest end (YYYY-MM-DD)"
        required: false
        default: "2025-12-31"
      bands:
        description: "Odds bands: dog=min,max;fav=min,max"
        required: false
        default: "dog=2.20,4.50;fav=1.15,2.00"
      grid:
        description: "Grid (min_edge=...;kelly_cap=...;te8_dog=...;te8_fav=...)"
        required: false
        default: "min_edge=0.02,0.03,0.04;kelly_cap=0.10,0.15,0.20;te8_dog=0.58,0.60;te8_fav=0.48,0.50"
      use_synth:
        description: "Seed example odds if none found"
        required: true
        type: choice
        options:
          - "yes"
          - "no"
        default: "yes"

permissions:
  contents: read

jobs:
  courtsense:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy requests unidecode tabulate openpyxl

      - name: Ensure folders
        run: |
          mkdir -p data/raw/odds data/raw/odds_normalized data

      # ----- NO HEREDOCS: write the seed CSV with Python -----
      - name: Seed sample odds if none
        if: ${{ github.event.inputs.use_synth == 'yes' }}
        run: |
          python - << 'PY'
          import os, csv
          path1 = "data/raw/odds"
          path2 = "data/raw/odds_normalized"
          has_files = any(os.scandir(path1)) if os.path.isdir(path1) else False
          has_norm  = any(os.scandir(path2)) if os.path.isdir(path2) else False
          if has_files or has_norm:
              print("Local odds exist, skipping seed.")
          else:
              os.makedirs(path1, exist_ok=True)
              rows = [
                ["date","player_a","player_b","odds_a","odds_b"],
                ["2023-06-11","Novak Djokovic","Casper Ruud","1.33","3.40"],
                ["2022-07-10","Novak Djokovic","Nick Kyrgios","1.33","3.60"],
                ["2021-09-12","Daniil Medvedev","Novak Djokovic","2.60","1.55"],
                ["2024-01-28","Jannik Sinner","Daniil Medvedev","1.85","2.05"],
                ["2021-06-12","Barbora Krejcikova","Anastasia Pavlyuchenkova","1.75","2.10"],
                ["2023-07-15","Marketa Vondrousova","Ons Jabeur","2.30","1.65"],
                ["2024-07-13","Barbora Krejcikova","Jasmine Paolini","1.60","2.40"],
              ]
              with open(os.path.join(path1,"sample_odds.csv"), "w", newline="", encoding="utf-8") as f:
                  csv.writer(f).writerows(rows)
              print("Seeded data/raw/odds/sample_odds.csv")
          PY

      - name: Build dataset (link odds to Sackmann + quick Elo) â€” always writes headers
        env:
          YEARS_CSV: ${{ github.event.inputs.years_csv }}
        run: |
          python - << 'PY'
          import os, io, time, glob, re, pandas as pd, requests
          from unidecode import unidecode

          years = os.getenv("YEARS_CSV") or "2021 2022 2023 2024 2025"
          YEARS = [int(y) for y in years.split()]

          def fetch(repo, tour, y):
              url=f"https://raw.githubusercontent.com/JeffSackmann/{repo}/master/{tour}_matches_{y}.csv"
              for _ in (0,1,2):
                  try:
                      r=requests.get(url, timeout=12); r.raise_for_status()
                      return pd.read_csv(io.StringIO(r.text))
                  except Exception:
                      time.sleep(1.0)
              return pd.DataFrame()

          atp = pd.concat([fetch("tennis_atp","atp",y) for y in YEARS], ignore_index=True)
          wta = pd.concat([fetch("tennis_wta","wta",y) for y in YEARS], ignore_index=True)

          def norm(s):
              s=unidecode(str(s)).lower()
              s=re.sub(r"[^a-z ]"," ",s)
              return re.sub(r"\s+"," ",s).strip()

          for df,t in ((atp,"ATP"),(wta,"WTA")):
              if df.empty: continue
              df["tour"]=t
              df["date"]=pd.to_datetime(df["tourney_date"].astype(str), format="%Y%m%d", errors="coerce").dt.normalize()
              df["w_norm"]=df["winner_name"].map(norm); df["l_norm"]=df["loser_name"].map(norm)
              df["pair"]=df.apply(lambda r: " vs ".join(sorted([r["w_norm"], r["l_norm"]])), axis=1)

          results = pd.concat([atp,wta], ignore_index=True)

          # quick Elo (pre-match)
          def build_elo(df):
              E={"ATP":{}, "WTA":{}}
              K=32
              for _,r in df.sort_values(["tour","date"]).iterrows():
                  t=r["tour"]; w=r["w_norm"]; l=r["l_norm"]
                  ew=E[t].get(w,1500.0); el=E[t].get(l,1500.0)
                  exp=1/(1+10**((el-ew)/400))
                  E[t][w]=ew+K*(1-exp); E[t][l]=el+K*(0-(1-exp))
              return E
          ELO = build_elo(results)

          os.makedirs("data", exist_ok=True)
          pd.DataFrame([{"player":k,"elo":v} for k,v in ELO["ATP"].items()]).to_csv("data/atp_elo.csv", index=False)
          pd.DataFrame([{"player":k,"elo":v} for k,v in ELO["WTA"].items()]).to_csv("data/wta_elo.csv", index=False)

          base = "data/raw/odds_normalized" if glob.glob("data/raw/odds_normalized/*.csv") else "data/raw/odds"
          files = glob.glob(base+"/*.csv")

          cols=["date","tour","tournament","round","player","opponent","odds","opp_odds","result","elo_player","elo_opponent","surface"]
          out = pd.DataFrame(columns=cols)

          if files and not results.empty:
              odds = pd.concat([pd.read_csv(p) for p in files], ignore_index=True)
              odds["date"]=pd.to_datetime(odds["date"], errors="coerce").dt.normalize()
              odds=odds.dropna(subset=["date","player_a","player_b","odds_a","odds_b"])

              def link_row(r):
                  pair=" vs ".join(sorted([norm(r["player_a"]), norm(r["player_b"])]))
                  cand = results[(results["pair"]==pair) &
                                 (results["date"].between(r["date"]-pd.Timedelta(days=10),
                                                          r["date"]+pd.Timedelta(days=10)))]
                  if cand.empty: return None
                  m = cand.iloc[(cand["date"]-r["date"]).abs().argsort().iloc[0]]
                  w,l = m["w_norm"], m["l_norm"]
                  pn  = norm(r["player_a"])
                  res = 1 if pn==w else 0
                  pool = ELO["ATP"] if m["tour"]=="ATP" else ELO["WTA"]
                  ep = pool.get(w,1500.0) if pn==w else pool.get(l,1500.0)
                  eo = pool.get(l,1500.0) if pn==w else pool.get(w,1500.0)
                  return {
                      "date": m["date"].date(), "tour": m["tour"], "tournament": m.get("tourney_name",""),
                      "round": m.get("round",""), "player": r["player_a"], "opponent": r["player_b"],
                      "odds": float(r["odds_a"]), "opp_odds": float(r["odds_b"]),
                      "result": int(res), "elo_player": ep, "elo_opponent": eo, "surface": m.get("surface","")
                  }

              rows=[x for x in (link_row(x) for _,x in odds.iterrows()) if x]
              out = pd.DataFrame(rows, columns=cols)

          out.to_csv("data/historical_matches.csv", index=False)  # ALWAYS headers
          print(f"Linked rows: {len(out)}")
          PY

      - name: Backtest (skip gracefully on 0 rows)
        run: |
          if [ ! -s data/historical_matches.csv ]; then
            echo "# TE8 Backtest Summary" > backtest_summary.md
            echo "" >> backtest_summary.md
            echo "_Dataset missing or empty._" >> backtest_summary.md
          else
            python - << 'PY'
            import pandas as pd
            df=pd.read_csv("data/historical_matches.csv")
            open("nrows.txt","w").write(str(len(df)))
            PY
            if [ "$(cat nrows.txt)" = "0" ]; then
              echo "# TE8 Backtest Summary" > backtest_summary.md
              echo "" >> backtest_summary.md
              echo "_No rows to backtest (0 linked games)._" >> backtest_summary.md
            else
              python backtest_te8.py \
                --input data/historical_matches.csv \
                --start "${{ github.event.inputs.start_date }}" \
                --end   "${{ github.event.inputs.end_date }}" \
                --bands "${{ github.event.inputs.bands }}" \
                --grid  "${{ github.event.inputs.grid }}" \
                --out-csv backtest_results.csv \
                --summary backtest_summary.md
            fi

      - name: Job summary
        run: |
          echo "## Courtsense" >> "$GITHUB_STEP_SUMMARY"
          if [ -f backtest_summary.md ]; then
            cat backtest_summary.md >> "$GITHUB_STEP_SUMMARY"
          else
            echo "_No summary produced._" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backtest-output
          path: |
            data/historical_matches.csv
            data/atp_elo.csv
            data/wta_elo.csv
            backtest_results.csv
            backtest_summary.md
            grid_results.csv
          if-no-files-found: warn
