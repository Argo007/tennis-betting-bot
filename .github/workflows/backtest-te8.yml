name: Backtest TrueEdge8 + Kelly

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: "Start date (YYYY-MM-DD)"
        required: true
        default: "2021-01-01"
      end_date:
        description: "End date (YYYY-MM-DD)"
        required: true
        default: "2024-12-31"
      years_csv:
        description: "Years to download (space separated)"
        required: true
        default: "2021 2022 2023 2024"
      te8_dog:
        description: "TE8 threshold for dogs"
        required: true
        default: "0.60"
      te8_fav:
        description: "TE8 threshold for favorites"
        required: true
        default: "0.50"
      bands:
        description: "Odds bands: dog=min,max;fav=min,max"
        required: true
        default: "dog=2.20,4.50;fav=1.15,2.00"
      dog_cap:
        description: "Dog micro-cap × Kelly"
        required: true
        default: "0.25"
      stake_unit:
        description: "Flat unit stake (€)"
        required: true
        default: "100"
      bankroll:
        description: "Starting bankroll for Kelly sim (€)"
        required: true
        default: "1000"
      tuners:
        description: "TE8 tuners: surface_boost=0.05;recent_form_weight=0.30;injury_penalty=0.15"
        required: true
        default: "surface_boost=0.05;recent_form_weight=0.30;injury_penalty=0.15"

jobs:
  backtest:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy openpyxl xlrd

      # --- Jeff Sackmann results to build Elo ---
      - name: Download ATP/WTA results (Jeff Sackmann)
        run: |
          mkdir -p sackmann
          for Y in ${{ inputs.years_csv }}; do
            curl -sSL -o sackmann/atp_matches_${Y}.csv https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_${Y}.csv
            curl -sSL -o sackmann/wta_matches_${Y}.csv https://raw.githubusercontent.com/JeffSackmann/tennis_wta/master/wta_matches_${Y}.csv
          done

      - name: Generate Elo (for backtest)
        run: |
          python - <<'PY'
          import pandas as pd, glob, os
          START, K = 1500.0, 32.0
          def exp(a,b): return 1/(1+10**((b-a)/400))
          def upd(a,b,s): return a + K*(s-exp(a,b))
          def calc(pattern):
              files = glob.glob(pattern)
              if not files: raise SystemExit("No match files for Elo.")
              df = pd.concat((pd.read_csv(f) for f in files), ignore_index=True)
              E={}
              for _,r in df.iterrows():
                  w,l = r.get('winner_name'), r.get('loser_name')
                  if not isinstance(w,str) or not isinstance(l,str): continue
                  ew,el = E.get(w,START), E.get(l,START)
                  E[w]=upd(ew,el,1.0); E[l]=upd(el,ew,0.0)
              return pd.DataFrame([{"player":k,"elo":v} for k,v in E.items()])
          os.makedirs("data", exist_ok=True)
          calc("sackmann/atp_matches_*.csv").to_csv("data/atp_elo.csv", index=False)
          calc("sackmann/wta_matches_*.csv").to_csv("data/wta_elo.csv", index=False)
          print("Elo files ready at data/atp_elo.csv and data/wta_elo.csv")
          PY

      # --- tennis-data: CSV or XLSX, multiple naming patterns ---
      - name: Download historical closing odds (tennis-data.co.uk)
        run: |
          set -e
          mkdir -p tennisdata
          for Y in ${{ inputs.years_csv }}; do
            for URL in \
              "https://www.tennis-data.co.uk/${Y}/ATP_${Y}.csv" \
              "https://www.tennis-data.co.uk/${Y}/ATP_${Y}.xlsx" \
              "https://www.tennis-data.co.uk/${Y}/WTA_${Y}.csv" \
              "https://www.tennis-data.co.uk/${Y}/WTA_${Y}.xlsx" \
              "https://www.tennis-data.co.uk/${Y}/${Y}.csv" \
              "https://www.tennis-data.co.uk/${Y}/${Y}.xlsx"
            do
              FN="tennisdata/$(basename "$URL")"
              echo "Trying $URL"
              if curl -sS -L -f "$URL" -o "$FN"; then
                echo "Saved -> $FN"
              fi
            done
          done
          echo "Downloaded files:"
          ls -l tennisdata || true

      # --- Build the unified historical_matches.csv for the backtester ---
      - name: Build historical_matches.csv
        run: |
          python - <<'PY'
          import os, glob, pandas as pd, numpy as np
          os.makedirs("data", exist_ok=True)

          def load_any(path):
            try:
              if path.lower().endswith(('.xlsx','.xls')):
                return pd.read_excel(path)
              return pd.read_csv(path)
            except Exception:
              try:
                return pd.read_csv(path, encoding="latin1")
              except Exception:
                return None

          frames=[]
          for path in glob.glob("tennisdata/*.*"):
            if not path.lower().endswith(('.csv','.xlsx','.xls')): 
              continue
            df = load_any(path)
            if df is None or df.empty:
              continue

            cols = {c.lower(): c for c in df.columns}
            if "date" not in cols or ("winner" not in cols and "w" not in cols):
              continue

            cDate = cols.get("date")
            cWin  = cols.get("winner", cols.get("w"))
            cLos  = cols.get("loser",  cols.get("l"))
            cPSW  = cols.get("psw")
            cPSL  = cols.get("psl")
            cAvgW = cols.get("avgw")
            cAvgL = cols.get("avgl")
            cSurf = cols.get("surface") if "surface" in cols else None

            d = pd.DataFrame({
                "date": pd.to_datetime(df[cDate], errors="coerce"),
                "winner": df[cWin].astype(str),
                "loser":  df[cLos].astype(str),
                "odds_w": pd.to_numeric(df[cPSW] if cPSW in df else df.get(cAvgW, np.nan), errors="coerce"),
                "odds_l": pd.to_numeric(df[cPSL] if cPSL in df else df.get(cAvgL, np.nan), errors="coerce"),
                "surface": df[cSurf].astype(str) if cSurf else ""
            }).dropna(subset=["date"])

            # fallback to averages if needed
            if d["odds_w"].isna().all() and cAvgW in df: d["odds_w"]=pd.to_numeric(df[cAvgW], errors="coerce")
            if d["odds_l"].isna().all() and cAvgL in df: d["odds_l"]=pd.to_numeric(df[cAvgL], errors="coerce")
            d = d.dropna(subset=["odds_w","odds_l"])

            tour = "ATP" if "ATP" in os.path.basename(path).upper() else ("WTA" if "WTA" in os.path.basename(path).upper() else "")
            if not tour: tour = "ATP"  # harmless default

            a = pd.DataFrame({
                "date": d["date"].dt.strftime("%Y-%m-%d"),
                "tour": tour,
                "player": d["winner"],
                "opponent": d["loser"],
                "best_odds": d["odds_w"],
                "result": 1,
                "surface": d["surface"]
            })
            b = pd.DataFrame({
                "date": d["date"].dt.strftime("%Y-%m-%d"),
                "tour": tour,
                "player": d["loser"],
                "opponent": d["winner"],
                "best_odds": d["odds_l"],
                "result": 0,
                "surface": d["surface"]
            })
            frames += [a,b]

          if not frames:
            print("No tennis-data files parsed.")
            raise SystemExit(1)

          out = pd.concat(frames, ignore_index=True)
          out = out.dropna(subset=["best_odds"])
          out["best_odds"] = pd.to_numeric(out["best_odds"], errors="coerce")
          out = out.dropna(subset=["best_odds"])
          out.to_csv("data/historical_matches.csv", index=False)
          print("Built data/historical_matches.csv with", len(out), "rows.")
          PY

      - name: Ensure injuries.json exists
        run: |
          if [ ! -f injuries.json ]; then
            cat > injuries.json <<'JSON'
            [
              {
                "player": "Holger Rune",
                "start_date": "2023-05-15",
                "end_date": "2023-06-02",
                "impact": 0.70,
                "note": "Example stub — adjust/remove as needed"
              }
            ]
            JSON
            echo "Created injuries.json stub."
          else
            echo "injuries.json present."
          fi

      - name: Parse bands & tuners; run backtest
        shell: bash
        run: |
          # Parse bands: dog=min,max;fav=min,max
          BANDS="${{ inputs.bands }}"
          DOG_BAND=$(echo "$BANDS" | sed -n 's/.*dog=\([^;]*\).*/\1/p'); [ -z "$DOG_BAND" ] && DOG_BAND="2.20,4.50"
          FAV_BAND=$(echo "$BANDS" | sed -n 's/.*fav=\([^;]*\).*/\1/p'); [ -z "$FAV_BAND" ] && FAV_BAND="1.15,2.00"

          # Parse tuners: surface_boost=...;recent_form_weight=...;injury_penalty=...
          TUNE="${{ inputs.tuners }}"
          SURF_BOOST=$(echo "$TUNE" | sed -n 's/.*surface_boost=\([^;]*\).*/\1/p'); [ -z "$SURF_BOOST" ] && SURF_BOOST="0.05"
          FORM_W=$(echo "$TUNE" | sed -n 's/.*recent_form_weight=\([^;]*\).*/\1/p'); [ -z "$FORM_W" ] && FORM_W="0.30"
          INJ_PEN=$(echo "$TUNE" | sed -n 's/.*injury_penalty=\([^;]*\).*/\1/p'); [ -z "$INJ_PEN" ] && INJ_PEN="0.15"

          test -f backtest_te8.py || { echo "::error ::backtest_te8.py missing in repo root"; exit 1; }

          python backtest_te8.py \
            --input data/historical_matches.csv \
            --elo-atp data/atp_elo.csv \
            --elo-wta data/wta_elo.csv \
            --injuries injuries.json \
            --start "${{ inputs.start_date }}" \
            --end   "${{ inputs.end_date }}" \
            --te8-dog "${{ inputs.te8_dog }}" \
            --te8-fav "${{ inputs.te8_fav }}" \
            --dog-band "$DOG_BAND" \
            --fav-band "$FAV_BAND" \
            --dog-cap "${{ inputs.dog_cap }}" \
            --stake-unit "${{ inputs.stake_unit }}" \
            --bankroll "${{ inputs.bankroll }}" \
            --surface-boost "$SURF_BOOST" \
            --recent-form-weight "$FORM_W" \
            --injury-penalty "$INJ_PEN" \
            --out-csv backtest_results.csv \
            --summary backtest_summary.md

      - name: Publish summary
        run: |
          if [ -f backtest_summary.md ]; then
            cat backtest_summary.md >> "$GITHUB_STEP_SUMMARY"
          else
            echo "_No backtest summary produced._" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload artifacts (CSV + MD)
        uses: actions/upload-artifact@v4
        with:
          name: backtest-output
          path: |
            backtest_results.csv
            backtest_summary.md
