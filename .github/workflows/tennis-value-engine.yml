name: Tennis Value Engine (Clean H2H)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "5 6 * * *"   # adjust to taste

permissions:
  contents: read

concurrency:
  group: tennis-value-engine
  cancel-in-progress: true

env:
  TZ: Europe/Amsterdam

jobs:
  picks:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests pytz

      # 1) Run YOUR model â€” it writes outputs/value_engine_shortlist.md (Markdown), not a CSV.
      - name: Run model (produces Markdown shortlist)
        env:
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
          LOOKAHEAD_HOURS: "24"
          REGIONS: "eu,uk,us,au"
          MARKETS: "h2h,spreads,totals"
          SPORT_KEYS: "tennis,tennis_atp,tennis_wta"
          KELLY_MIN: "0.05"
          EV_MIN: "0.00"
          MIN_CONF: "0.40"
          OUT_DIR: "outputs"
          SHORTLIST_FILE: "value_engine_shortlist.md"
        run: |
          set -euo pipefail
          python tennis_value_engine.py
          test -f outputs/value_engine_shortlist.md || { echo "Shortlist MD not found."; exit 1; }

      - name: List workspace (debug)
        run: |
          echo "==== ls -R (top 3 levels) ===="
          find . -maxdepth 3 -type f | sed 's|^\./||' | sort
          echo "==============================="

      # 2) Convert the Markdown table -> CSV (Tennis Value Engine Unified.csv)
      - name: Convert shortlist MD to CSV
        run: |
          python - <<'PY'
          import pandas as pd, re, os, sys
          md_path = "outputs/value_engine_shortlist.md"
          if not os.path.exists(md_path):
              print("ERROR: Markdown shortlist not found:", md_path, file=sys.stderr); sys.exit(1)
          lines = [l.rstrip("\n") for l in open(md_path, encoding="utf-8")]
          # find header row
          start = None
          for i,l in enumerate(lines):
              if l.strip().startswith("| Tour | Market | Selection | Opponent | Odds | p_model | p_fair | EV/u | Kelly | Conf | Bet | Start (UTC) | Books | Source |"):
                  start = i; break
          if start is None:
              print("ERROR: Could not find table header in shortlist.", file=sys.stderr); sys.exit(1)
          header = [c.strip() for c in lines[start].strip().strip("|").split("|")]
          data = []
          i = start + 2  # skip the separator row like |---|---|...
          while i < len(lines):
              l = lines[i].strip()
              if not l or not l.startswith("|"): break
              if l.startswith("|---"):  # safety
                  i += 1; continue
              parts = [c.strip() for c in l.strip().strip("|").split("|")]
              if len(parts) != len(header): break
              data.append(dict(zip(header, parts)))
              i += 1
          if not data:
              print("WARNING: No rows parsed from shortlist table.")
          df = pd.DataFrame(data)
          # coerce numerics where sensible
          for col in ["Odds","p_model","p_fair","EV/u","Kelly","Conf"]:
              if col in df.columns:
                  df[col] = pd.to_numeric(df[col].replace({"": None}), errors="coerce")
          out_csv = "Tennis Value Engine Unified.csv"
          df.to_csv(out_csv, index=False)
          print("Wrote", out_csv, "rows:", len(df))
          PY

      # 3) Filter H2H + Kelly/EV, dedupe per matchup, publish summary
      - name: Filter & dedupe H2H; publish summary
        run: |
          python - <<'PY'
          import pandas as pd, glob, os, sys, re

          def norm(s): return re.sub(r'[^a-z0-9]', '', str(s).lower())

          # find CSVs (prefer our unified CSV)
          csvs = glob.glob("**/*.csv", recursive=True)
          if not csvs:
            print("ERROR: No CSV files found.", file=sys.stderr); sys.exit(1)
          def score(p):
            b = norm(os.path.basename(p))
            prefer = all(k in b for k in ["tennis","value","engine","unified"])
            return (prefer, os.path.getsize(p))
          csvs.sort(key=score, reverse=True)
          src = csvs[0]
          df = pd.read_csv(src)

          # tolerant map
          def col(df, *names):
            for n in names:
              if n in df.columns: return n
            # case-insensitive
            lower = {c.lower(): c for c in df.columns}
            for n in names:
              if n.lower() in lower: return lower[n.lower()]
            raise KeyError(f"Missing column: {names}")
          c_market   = col(df, "Market","market")
          c_sel      = col(df, "Selection","selection")
          c_opp      = col(df, "Opponent","opponent")
          c_kelly    = col(df, "Kelly","kelly")
          c_evu      = col(df, "EV/u","evu","EVU","EV")
          c_odds     = df.columns[df.columns.str.lower().eq("odds")][0] if any(df.columns.str.lower().eq("odds")) else None

          # numeric coercion
          df[c_kelly] = pd.to_numeric(df[c_kelly], errors="coerce")
          df[c_evu]   = pd.to_numeric(df[c_evu], errors="coerce")
          if c_odds: df[c_odds] = pd.to_numeric(df[c_odds], errors="coerce")

          # 1) H2H only
          df = df[df[c_market].astype(str).str.upper().eq("H2H")].copy()
          # 2) filters
          df = df[(df[c_kelly] > 0.05) & (df[c_evu] > 0)].copy()

          # 3) dedupe by unordered matchup
          def pair_key(a,b):
            a,b = str(a).strip(), str(b).strip()
            return " | ".join(sorted([a,b]))
          df["__pair__"] = [pair_key(a,b) for a,b in zip(df[c_sel], df[c_opp])]

          sort_cols, asc = [c_kelly, c_evu], [False, False]
          if c_odds: sort_cols.append(c_odds); asc.append(False)
          df.sort_values(sort_cols, ascending=asc, inplace=True)
          df = df.drop_duplicates(["__pair__"], keep="first").copy()
          df.drop(columns="__pair__", inplace=True)

          # finalize columns & flag
          df["Bet"] = "YES"
          preferred = ['Tour','Market','Selection','Opponent','Odds','p_model','p_fair','EV/u','Kelly','Conf','Bet','Start (UTC)','Books','Source']
          cols_out = [c for c in preferred if c in df.columns] or df.columns.tolist()
          df = df[cols_out]

          out_csv = "value_filtered_h2h.csv"
          df.to_csv(out_csv, index=False)

          def gfm(t):
            if t.empty: return "_No H2H picks passed filters._"
            lines = ["| " + " | ".join(t.columns) + " |",
                     "| " + " | ".join(["---"]*len(t.columns)) + " |"]
            for _, r in t.iterrows():
              lines.append("| " + " | ".join(str(r[c]) for c in t.columns) + " |")
            return "\n".join(lines)

          with open(os.environ.get("GITHUB_STEP_SUMMARY","/tmp/gh_summary.md"), "a") as fh:
            fh.write(f"# Clean H2H Picks (source: {src})\n\n" + gfm(df) + "\n")
          print(f"Source: {src} -> value_filtered_h2h.csv (rows kept: {len(df)})")
          PY

      - name: Upload filtered picks
        uses: actions/upload-artifact@v4
        with:
          name: value_filtered_h2h
          path: value_filtered_h2h.csv
          if-no-files-found: error
