name: Tennis Value Engine (Clean H2H)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "5 6 * * *"

permissions:
  contents: read

concurrency:
  group: tennis-value-engine
  cancel-in-progress: true

env:
  TZ: Europe/Amsterdam

jobs:
  picks:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pandas

      # >>> Replace the command below with YOUR script that creates a CSV (e.g., value.csv)
      - name: Run model
        env:
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
        run: |
          set -euo pipefail
          # EXAMPLE (replace with your real command):
          # python tennis_value_engine.py --out value.csv
          test -f value.csv || { echo "ERROR: value.csv not found. Your model step must create it."; exit 1; }

      - name: Filter & dedupe H2H; publish summary
        run: |
          python - <<'PY'
          import pandas as pd, glob, os, sys, re

          def normalize_col(s: str) -> str:
              return re.sub(r'[^a-z0-9]', '', str(s).lower())

          def remap_columns(df):
              want = {
                  'selection': ['selection','player','pick'],
                  'opponent':  ['opponent','opp'],
                  'market':    ['market','mkt'],
                  'kelly':     ['kelly','kellyfraction','k'],
                  'ev/u':      ['ev/u','evu','evperu','ev','edge'],
                  'odds':      ['odds','price','decimalodds'],
                  'p_model':   ['p_model','pmodel','prob','prob_model'],
                  'p_fair':    ['pfair','p_fair','prob_fair','fairprob'],
              }
              norm_map = {normalize_col(c): c for c in df.columns}
              out = {}
              for canon, aliases in want.items():
                  for a in aliases:
                      if a in norm_map:
                          out[canon] = norm_map[a]
                          break
              required = ['selection','opponent','market','kelly','ev/u']
              missing = [r for r in required if r not in out]
              if missing:
                  raise SystemExit(f"Missing required columns: {missing}")
              return out

          # find a CSV produced by your model
          cands = [p for p in glob.glob("**/*.csv", recursive=True)
                   if os.path.basename(p).lower().startswith(("value","picks","tennis"))]
          if not cands:
              print("No CSV found (looking for value*/picks*/tennis*).", file=sys.stderr); sys.exit(1)

          df = None
          for f in cands:
              try:
                  d = pd.read_csv(f)
                  cols = remap_columns(d)
                  df, input_csv = d.copy(), f
                  break
              except Exception:
                  continue
          if df is None:
              print("CSV found but missing required columns.", file=sys.stderr); sys.exit(1)

          # coerce numeric
          for c in [cols['kelly'], cols['ev/u']]:
              df[c] = pd.to_numeric(df[c], errors='coerce')
          if 'odds' in cols:
              df[cols['odds']] = pd.to_numeric(df[cols['odds']], errors='coerce')

          # 1) H2H only
          df = df[df[cols['market']].astype(str).str.upper().eq('H2H')].copy()
          # 2) filters
          df = df[(df[cols['kelly']] > 0.05) & (df[cols['ev/u']] > 0)].copy()

          # 3) dedupe by unordered pair (keep highest Kelly, then EV/u, then Odds)
          def pair_key(a,b):
              a, b = str(a).strip(), str(b).strip()
              return " | ".join(sorted([a,b]))
          df['__pair__'] = [pair_key(a,b) for a,b in zip(df[cols['selection']], df[cols['opponent']])]

          sort_keys = [cols['kelly'], cols['ev/u']]
          asc = [False, False]
          if 'odds' in cols: sort_keys.append(cols['odds']); asc.append(False)
          df.sort_values(sort_keys, ascending=asc, inplace=True)
          df = df.drop_duplicates(['__pair__'], keep='first').copy()
          df.drop(columns='__pair__', inplace=True)

          df['Bet'] = 'YES'

          rename = {
            cols['market']: 'Market',
            cols['selection']: 'Selection',
            cols['opponent']: 'Opponent',
            cols['kelly']: 'Kelly',
            cols['ev/u']: 'EV/u'
          }
          if 'odds' in cols:    rename[cols['odds']] = 'Odds'
          if 'p_model' in cols: rename[cols['p_model']] = 'p_model'
          if 'p_fair' in cols:  rename[cols['p_fair']]  = 'p_fair'
          df = df.rename(columns=rename)

          preferred = ['Tour','Market','Selection','Opponent','Odds','p_model','p_fair','EV/u','Kelly','Conf','Bet','Start (UTC)','Books','Source']
          cols_out = [c for c in preferred if c in df.columns] or df.columns.tolist()
          df = df[cols_out]

          out_csv = "value_filtered_h2h.csv"
          df.to_csv(out_csv, index=False)

          def gfm(t):
              if t.empty: return "_No H2H picks passed filters._"
              lines = ["| " + " | ".join(t.columns) + " |",
                       "| " + " | ".join(["---"]*len(t.columns)) + " |"]
              for _, r in t.iterrows():
                  lines.append("| " + " | ".join(str(r[c]) for c in t.columns) + " |")
              return "\n".join(lines)
          with open(os.environ.get("GITHUB_STEP_SUMMARY","/tmp/gh_summary.md"), "a") as fh:
              fh.write("# Tennis Value Engine â€” Clean H2H Picks\n\n" + gfm(df) + "\n")

          print(f"Kept {len(df)} rows -> value_filtered_h2h.csv")
          PY

      - name: Upload filtered picks
        uses: actions/upload-artifact@v4
        with:
          name: value_filtered_h2h
          path: value_filtered_h2h.csv
          if-no-files-found: error
