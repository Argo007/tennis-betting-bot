name: Tennis Value Engine (Daily Picks)

on:
  schedule:
    - cron: "0 7 * * *"         # every day 07:00 UTC
  workflow_dispatch:
    inputs:
      lookahead_h:
        description: "Odds freshness window (hours)"
        required: false
        default: "6"
      min_conf:
        description: "Minimum model confidence (0–1)"
        required: false
        default: "0.58"
      bankroll:
        description: "Starting bankroll for Kelly"
        required: false
        default: "1000"
      max_picks:
        description: "Max picks to publish"
        required: false
        default: "20"
      publish_md:
        description: "Publish markdown summary to job log?"
        required: true
        type: choice
        default: "yes"
        options: ["yes","no"]

permissions:
  contents: read

env:
  TZ: Europe/Amsterdam
  LOOKAHEAD_H: ${{ github.event.inputs.lookahead_h || '6' }}
  MIN_CONF:    ${{ github.event.inputs.min_conf    || '0.58' }}
  BANKROLL:    ${{ github.event.inputs.bankroll    || '1000' }}
  MAX_PICKS:   ${{ github.event.inputs.max_picks   || '20' }}
  PUBLISH_MD:  ${{ github.event.inputs.publish_md  || 'yes' }}

jobs:
  value-engine:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install \
            pandas numpy requests pyyaml tabulate openpyxl \
            matplotlib unidecode rapidfuzz

      # --- Optional: quick sanity ping so we fail fast if scripts moved ---
      - name: Verify scripts present
        run: |
          test -f tennis_value_engine.py || echo "::warning ::tennis_value_engine.py not found (skipping this stage)"
          test -f tennis_value_picks_pro.py || { echo "::error ::tennis_value_picks_pro.py not found at repo root"; exit 1; }

      # --- Run your odds scan / model pipeline (make this whatever your repo expects) ---
      - name: Run value engine (predict + shortlist)
        shell: bash
        run: |
          set -euo pipefail

          LOG=outputs/engine_run.log
          mkdir -p outputs data

          # If you have a pre-engine step, keep it; otherwise this is a no-op.
          if [ -f tennis_value_engine.py ]; then
            echo "Running tennis_value_engine.py ..." | tee -a "$LOG"
            python tennis_value_engine.py \
              --lookahead "${LOOKAHEAD_H}" \
              --min-conf "${MIN_CONF}" \
              --out outputs/value_candidates.csv 2>&1 | tee -a "$LOG"
          else
            echo "No tennis_value_engine.py detected; assuming candidates come from picks_pro." | tee -a "$LOG"
          fi

          echo "Running tennis_value_picks_pro.py ..." | tee -a "$LOG"
          # This script is assumed to write value_picks_pro.csv
          python tennis_value_picks_pro.py \
            --lookahead "${LOOKAHEAD_H}" \
            --min-conf "${MIN_CONF}" \
            --bankroll "${BANKROLL}" \
            --max-picks "${MAX_PICKS}" 2>&1 | tee -a "$LOG"

          # If script didn't write the file, make an empty but valid CSV so the job doesn't blow up
          test -f value_picks_pro.csv || {
            echo "date,tour,tournament,round,player,opponent,odds,edge,kelly,stake,model_conf" > value_picks_pro.csv
            echo "::warning ::No picks produced; created empty value_picks_pro.csv" | tee -a "$LOG"
          }

      # --- Build a clean markdown summary (never crash on empty/missing) ---
      - name: Build & publish summary
        run: |
          python - <<'PY'
          import os, pandas as pd, json
          picks_path="value_picks_pro.csv"
          md=["# Tennis Value Engine — Daily Picks"]
          if os.path.exists(picks_path):
            try:
              df=pd.read_csv(picks_path)
            except Exception as e:
              md.append(f"\n_Unable to read picks CSV: {e}_")
              df=pd.DataFrame()
          else:
            df=pd.DataFrame()
          n=len(df)
          md.append(f"\n- Lookahead: **{os.getenv('LOOKAHEAD_H')}h**")
          md.append(f"- Min confidence: **{os.getenv('MIN_CONF')}**")
          md.append(f"- Bankroll: **€{float(os.getenv('BANKROLL','1000')):,.2f}**")
          md.append(f"- Max picks: **{os.getenv('MAX_PICKS')}**")
          md.append(f"- Rows in picks: **{n}**")

          if n>0:
            cols=[c for c in ["date","tour","tournament","round","player","opponent","odds","edge","kelly","stake","model_conf"] if c in df.columns]
            df= df[cols].copy()
            df.sort_values(["date","tour","tournament","round","player"], inplace=True)
            # Show top 25 in summary to keep it readable
            head=df.head(25)
            try:
              table=head.to_markdown(index=False)
            except Exception:
              table=head.to_csv(index=False)
            md.append("\n## Top picks (first 25)\n\n"+table)
          else:
            md.append("\n_No picks met the filters today._")

          out="\n".join(md)
          open("outputs/picks_summary.md","w").write(out)
          PY

          if [ "${PUBLISH_MD}" = "yes" ] && [ -f outputs/picks_summary.md ]; then
            echo "" >> "$GITHUB_STEP_SUMMARY"
            cat outputs/picks_summary.md >> "$GITHUB_STEP_SUMMARY"
          fi

      # --- Upload artifacts for download ---
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: value-engine-output
          path: |
            value_picks_pro.csv
            outputs/*.md
            outputs/*.log
          if-no-files-found: warn
